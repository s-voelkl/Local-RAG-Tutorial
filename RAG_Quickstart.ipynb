{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Start: RAG with Chroma + Ollama (Python)\n",
        "\n",
        "This Jupyter Notebook guides you through building a Retrieval Augmented Generation (RAG) pipeline using **Chroma** for vector storage and **Ollama** for embeddings + LLM generation.\n",
        "\n",
        "**CSV Structure (expected):**\n",
        "```csv\n",
        "TicketId,Project,Question,Answer\n",
        "1001,CRM Suite,Cannot log into the CRM; getting 'invalid credentials' even though my password is correct.,\"We reset the user's password, cleared browser cache, and verified SSO token freshness. Issue resolved.\"\n",
        "```\n",
        "\n",
        "---\n",
        "## Prerequisites\n",
        "- Install & run **Ollama**: `ollama serve` and pull models (e.g., `ollama pull llama3.1`, `ollama pull nomic-embed-text`).\n",
        "- Install Python packages: `pip install chromadb pandas ollama`.\n",
        "- Place your CSV file (e.g., `tickets.csv`) in the same working directory as this notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Imports & Configuration\n",
        "Set paths, model names, and retrieval parameters. Adjust as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Vector DB (Chroma)\n",
        "import chromadb\n",
        "\n",
        "# Ollama Python client for embeddings + generation\n",
        "import ollama\n",
        "\n",
        "# Configuration (edit as needed)\n",
        "CSV_PATH = \"tickets.csv\"  # Path to your CSV file\n",
        "CHROMA_DIR = \"./chroma_store\"  # Persistent directory for Chroma\n",
        "COLLECTION_NAME = \"tickets_qa\"\n",
        "EMBED_MODEL = \"nomic-embed-text\"  # Ollama embedding model\n",
        "LLM_MODEL = \"llama3.1:latest\"  # Ollama chat/generation model (e.g., 'mistral')\n",
        "\n",
        "TOP_K = 3  # Number of closest documents to fetch\n",
        "EMBED_BATCH = 32  # (Not used directly; simple loop embedding)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Helper Functions\n",
        "Embedding, document formatting, CSV loading, Chroma initialization, ingestion, retrieval, prompt building, and generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def embed_texts_ollama(texts, model=EMBED_MODEL):\n",
        "    \"\"\"\n",
        "    Embed a list of strings using Ollama's embeddings endpoint.\n",
        "    Returns list of vectors (list[float]).\n",
        "    NOTE: Ensure `ollama serve` is running and the embedding model is pulled.\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    for t in texts:\n",
        "        resp = ollama.embeddings(model=model, prompt=t)\n",
        "        vectors.append(resp[\"embedding\"])\n",
        "        time.sleep(0.01)  # gentle pacing\n",
        "    return vectors\n",
        "\n",
        "def row_to_document(row):\n",
        "    \"\"\"\n",
        "    Construct a semantically rich text representation to improve similarity search.\n",
        "    Combines Question + Answer + metadata.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        f\"TicketId: {row['TicketId']}\\n\"\n",
        "        f\"Project: {row['Project']}\\n\"\n",
        "        f\"Question: {row['Question']}\\n\"\n",
        "        f\"Resolution: {row['Answer']}\\n\"\n",
        "    )\n",
        "\n",
        "def load_csv(csv_path):\n",
        "    \"\"\"\n",
        "    Load the CSV with expected columns.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    required_cols = {\"TicketId\", \"Project\", \"Question\", \"Answer\"}\n",
        "    if not required_cols.issubset(df.columns):\n",
        "        raise ValueError(f\"CSV missing required columns: {required_cols}\")\n",
        "    df[\"TicketId\"] = df[\"TicketId\"].astype(str)\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_or_create_collection(persist_dir, collection_name):\n",
        "    \"\"\"\n",
        "    Create a persistent Chroma client + collection using the new client API.\n",
        "    This stores data on disk at `persist_dir`.\n",
        "    \"\"\"\n",
        "    # Use PersistentClient for local on-disk storage (SQLite-backed in current releases)\n",
        "    client = chromadb.PersistentClient(path=persist_dir)\n",
        "    collection = client.get_or_create_collection(name=collection_name)\n",
        "    return client, collection\n",
        "\n",
        "\n",
        "def ingest_dataframe(collection, df):\n",
        "    \"\"\"\n",
        "    Create embeddings for each row and upsert into Chroma.\n",
        "    \"\"\"\n",
        "    ids = df[\"TicketId\"].tolist()\n",
        "    documents = [row_to_document(r) for _, r in df.iterrows()]\n",
        "    metadatas = [\n",
        "        {\n",
        "            \"TicketId\": r[\"TicketId\"],\n",
        "            \"Project\": r[\"Project\"],\n",
        "            \"Question\": r[\"Question\"],\n",
        "            \"Answer\": r[\"Answer\"]\n",
        "        }\n",
        "        for _, r in df.iterrows()\n",
        "    ]\n",
        "    embeddings = embed_texts_ollama(documents, model=EMBED_MODEL)\n",
        "    collection.upsert(\n",
        "        ids=ids,\n",
        "        documents=documents,\n",
        "        metadatas=metadatas,\n",
        "        embeddings=embeddings,\n",
        "    )\n",
        "\n",
        "def retrieve_context(collection, query, top_k=TOP_K):\n",
        "    \"\"\"\n",
        "    Embed the query, then perform similarity search in Chroma.\n",
        "    Returns list of dicts with metadata + document + distance.\n",
        "    \"\"\"\n",
        "    query_vec = embed_texts_ollama([query], model=EMBED_MODEL)[0]\n",
        "    results = collection.query(\n",
        "        query_embeddings=[query_vec],\n",
        "        n_results=top_k,\n",
        "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
        "    )\n",
        "    contexts = []\n",
        "    for i in range(len(results[\"documents\"][0])):\n",
        "        contexts.append({\n",
        "            \"document\": results[\"documents\"][0][i],\n",
        "            \"metadata\": results[\"metadatas\"][0][i],\n",
        "            \"distance\": results[\"distances\"][0][i],\n",
        "        })\n",
        "    return contexts\n",
        "\n",
        "def build_augmented_prompt(user_query, contexts):\n",
        "    \"\"\"\n",
        "    Combine retrieved context into a single prompt for the LLM.\n",
        "    \"\"\"\n",
        "    context_texts = []\n",
        "    for c in contexts:\n",
        "        meta = c[\"metadata\"]\n",
        "        ctx = (\n",
        "            f\"- TicketId: {meta.get('TicketId')}\\n\"\n",
        "            f\"  Project: {meta.get('Project')}\\n\"\n",
        "            f\"  Question: {meta.get('Question')}\\n\"\n",
        "            f\"  Resolution: {meta.get('Answer')}\\n\"\n",
        "        )\n",
        "        context_texts.append(ctx)\n",
        "    context_block = \"\\n\".join(context_texts)\n",
        "    system_instructions = (\n",
        "        \"You are a helpful support assistant. Use the CONTEXT to answer the USER QUERY.\\n\"\n",
        "        \"If the context is not sufficient, say what additional info is needed.\\n\"\n",
        "        \"Cite TicketIds or Projects when relevant.\"\n",
        "    )\n",
        "    prompt = (\n",
        "        f\"{system_instructions}\\n\\n\"\n",
        "        f\"CONTEXT:\\n{context_block}\\n\\n\"\n",
        "        f\"USER QUERY:\\n{user_query}\\n\\n\"\n",
        "        f\"ASSISTANT:\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "def generate_with_ollama(prompt, model=LLM_MODEL):\n",
        "    \"\"\"\n",
        "    Call Ollama to generate a completion.\n",
        "    \"\"\"\n",
        "    resp = ollama.generate(model=model, prompt=prompt)\n",
        "    return resp[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load CSV\n",
        "Checks columns, casts `TicketId` to string for ID consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TicketId</th>\n",
              "      <th>Project</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001</td>\n",
              "      <td>CRM Suite</td>\n",
              "      <td>Cannot log into the CRM; getting 'invalid cred...</td>\n",
              "      <td>We reset the user's password, cleared browser ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002</td>\n",
              "      <td>Billing Portal</td>\n",
              "      <td>Invoice PDF fails to download; the button spin...</td>\n",
              "      <td>Enabled CDN path for PDF endpoint and added a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1003</td>\n",
              "      <td>Mobile App</td>\n",
              "      <td>App crashes when opening notifications on Andr...</td>\n",
              "      <td>Patched NotificationManager usage and added nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1004</td>\n",
              "      <td>Data Platform</td>\n",
              "      <td>Scheduled ETL job did not run last night; data...</td>\n",
              "      <td>Restarted Airflow scheduler, re-ran backfill, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1005</td>\n",
              "      <td>Helpdesk</td>\n",
              "      <td>Password reset emails are not being delivered ...</td>\n",
              "      <td>DKIM record was misconfigured. Fixed DNS recor...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  TicketId         Project                                           Question  \\\n",
              "0     1001       CRM Suite  Cannot log into the CRM; getting 'invalid cred...   \n",
              "1     1002  Billing Portal  Invoice PDF fails to download; the button spin...   \n",
              "2     1003      Mobile App  App crashes when opening notifications on Andr...   \n",
              "3     1004   Data Platform  Scheduled ETL job did not run last night; data...   \n",
              "4     1005        Helpdesk  Password reset emails are not being delivered ...   \n",
              "\n",
              "                                              Answer  \n",
              "0  We reset the user's password, cleared browser ...  \n",
              "1  Enabled CDN path for PDF endpoint and added a ...  \n",
              "2  Patched NotificationManager usage and added nu...  \n",
              "3  Restarted Airflow scheduler, re-ran backfill, ...  \n",
              "4  DKIM record was misconfigured. Fixed DNS recor...  "
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the CSV (ensure the file exists in the working directory)\n",
        "df = load_csv(CSV_PATH)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Chroma (Persistent)\n",
        "Creates/gets a collection and ensures data survives restarts (`duckdb+parquet`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Collection(name=tickets_qa)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client, collection = get_or_create_collection(CHROMA_DIR, COLLECTION_NAME)\n",
        "collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Ingest: Embed & Upsert\n",
        "Computes embeddings using **Ollama** and upserts into **Chroma** with metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding & upserting documents into Chroma...\n",
            "Ingestion complete. Data is persisted automatically at: ./chroma_store\n"
          ]
        }
      ],
      "source": [
        "print(\"Embedding & upserting documents into Chroma...\")\n",
        "ingest_dataframe(collection, df)\n",
        "\n",
        "# No manual persist step is required with PersistentClient.\n",
        "# Data is automatically stored at the path you passed to PersistentClient.\n",
        "print(\"Ingestion complete. Data is persisted automatically at:\", CHROMA_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Retrieve Relevant Context\n",
        "Embeds the user query, runs similarity search, and shows top results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top retrieved contexts:\n",
            "[1] TicketId=1001 | Project=CRM Suite | distance=131.9055\n",
            "[2] TicketId=1005 | Project=Helpdesk | distance=303.9214\n",
            "[3] TicketId=1007 | Project=HR Portal | distance=337.5979\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'document': \"TicketId: 1001\\nProject: CRM Suite\\nQuestion: Cannot log into the CRM; getting 'invalid credentials' even though my password is correct.\\nResolution: We reset the user's password, cleared browser cache, and verified SSO token freshness. Issue resolved.\\n\",\n",
              "  'metadata': {'Project': 'CRM Suite',\n",
              "   'TicketId': '1001',\n",
              "   'Answer': \"We reset the user's password, cleared browser cache, and verified SSO token freshness. Issue resolved.\",\n",
              "   'Question': \"Cannot log into the CRM; getting 'invalid credentials' even though my password is correct.\"},\n",
              "  'distance': 131.90553283691406},\n",
              " {'document': 'TicketId: 1005\\nProject: Helpdesk\\nQuestion: Password reset emails are not being delivered to users.\\nResolution: DKIM record was misconfigured. Fixed DNS records and retried the mail queue. Delivery confirmed.\\n',\n",
              "  'metadata': {'Project': 'Helpdesk',\n",
              "   'Answer': 'DKIM record was misconfigured. Fixed DNS records and retried the mail queue. Delivery confirmed.',\n",
              "   'TicketId': '1005',\n",
              "   'Question': 'Password reset emails are not being delivered to users.'},\n",
              "  'distance': 303.92144775390625}]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_query = (\n",
        "    \"A user reports invalid credentials in CRM but is sure the password is correct. What should we do?\"\n",
        ")\n",
        "contexts = retrieve_context(collection, user_query, top_k=TOP_K)\n",
        "print(\"Top retrieved contexts:\")\n",
        "for i, c in enumerate(contexts, 1):\n",
        "    print(f\"[{i}] TicketId={c['metadata']['TicketId']} | Project={c['metadata']['Project']} | distance={c['distance']:.4f}\")\n",
        "contexts[:2]  # preview first two\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Build Augmented Prompt\n",
        "Combines retrieved context with instructions for grounded answering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are a helpful support assistant. Use the CONTEXT to answer the USER QUERY.\n",
            "If the context is not sufficient, say what additional info is needed.\n",
            "Cite TicketIds or Projects when relevant.\n",
            "\n",
            "CONTEXT:\n",
            "- TicketId: 1001\n",
            "  Project: CRM Suite\n",
            "  Question: Cannot log into the CRM; getting 'invalid credentials' even though my password is correct.\n",
            "  Resolution: We reset the user's password, cleared browser cache, and verified SSO token freshness. Issue resolved.\n",
            "\n",
            "- TicketId: 1005\n",
            "  Project: Helpdesk\n",
            "  Question: Password reset emails are not being delivered to users.\n",
            "  Resolution: DKIM record was misconfigured. Fixed DNS records and retried the mail queue. Delivery confirmed.\n",
            "\n",
            "- TicketId: 1007\n",
            "  Project: HR Portal\n",
            "  Question: Employees cannot upload documents; the upload fails with a 413 error.\n",
            "  R\n",
            "...[truncated]...\n"
          ]
        }
      ],
      "source": [
        "prompt = build_augmented_prompt(user_query, contexts)\n",
        "print(prompt[:800] + (\"\\n...[truncated]...\" if len(prompt) > 800 else \"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Generate with Ollama LLM\n",
        "Calls the chosen chat/generation model to produce an answer grounded in the retrieved context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- LLM Answer ---\n",
            "Based on the provided context, I would recommend following the steps taken in TicketId 1001 to resolve the issue.\n",
            "\n",
            "To confirm, let's try:\n",
            "\n",
            "1. Reset the user's password\n",
            "2. Clear browser cache\n",
            "3. Verify SSO token freshness\n",
            "\n",
            "If these steps do not resolve the issue, please provide more information about the error message or any other symptoms you're experiencing, and I'll be happy to help further!\n"
          ]
        }
      ],
      "source": [
        "answer = generate_with_ollama(prompt, model=LLM_MODEL)\n",
        "print(\"--- LLM Answer ---\")\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. (Optional) Re-ingest / Reset Collection\n",
        "You can clear and re-ingest if you iterate on the dataset or embedding strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to clear collection\n",
        "# collection.delete(where={})  # deletes all documents\n",
        "# ingest_dataframe(collection, df)\n",
        "# client.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes & Tips\n",
        "- Use the **same embedding model** for documents and queries.\n",
        "- Ensure `ollama serve` is running and models are pulled.\n",
        "- For longer tickets, consider **chunking** documents (split into smaller parts).\n",
        "- You can filter by metadata in Chroma (e.g., `where={\"Project\": \"CRM Suite\"}`).\n",
        "\n",
        "## Next Steps\n",
        "- Add feedback logging, re-ranking, and prompt templates.\n",
        "- Wrap in an API (FastAPI) or CLI for production use.\n",
        "- Use PyMuPDF and Tesseract to get data from PDFs.\n",
        "- Use LlamaIndex for chunking the long PDF-texts into smaller pieces using semantic chunking.\n",
        "- Use FastAPI and docker for deploying a webserver"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
